{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a159d8",
   "metadata": {},
   "source": [
    "# üß† KNN Classifier: Full Train vs Test Metrics with K-Fold CV and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e746f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn_kfold(k_neighbors=5):\n",
    "    metrics = {\n",
    "        'train': {'accuracy': [], 'precision': [], 'recall': [], 'f1_macro': [], 'f1_weighted': [], 'f1_class0': [], 'f1_class1': []},\n",
    "        'test': {'accuracy': [], 'precision': [], 'recall': [], 'f1_macro': [], 'f1_weighted': [], 'f1_class0': [], 'f1_class1': []}\n",
    "    }\n",
    "    label_column = 'y'\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        train_path = f'kfold_fold_{i}_train.csv'\n",
    "        test_path = f'kfold_fold_{i}_test.csv'\n",
    "        df_train = pd.read_csv(train_path)\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        X_train = df_train.drop(label_column, axis=1)\n",
    "        y_train = df_train[label_column]\n",
    "        X_test = df_test.drop(label_column, axis=1)\n",
    "        y_test = df_test[label_column]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        for dataset, X, y_true, y_pred in [('train', X_train, y_train, y_train_pred), ('test', X_test, y_test, y_test_pred)]:\n",
    "            metrics[dataset]['accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "            metrics[dataset]['precision'].append(precision_score(y_true, y_pred, zero_division=0))\n",
    "            metrics[dataset]['recall'].append(recall_score(y_true, y_pred, zero_division=0))\n",
    "            metrics[dataset]['f1_macro'].append(f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "            metrics[dataset]['f1_weighted'].append(f1_score(y_true, y_pred, average='weighted', zero_division=0))\n",
    "            metrics[dataset]['f1_class0'].append(f1_score(y_true, y_pred, pos_label=0, zero_division=0))\n",
    "            metrics[dataset]['f1_class1'].append(f1_score(y_true, y_pred, pos_label=1, zero_division=0))\n",
    "\n",
    "        print(f\"Fold {i} - Train Accuracy: {metrics['train']['accuracy'][-1]:.4f}, Test Accuracy: {metrics['test']['accuracy'][-1]:.4f}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c542751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "train_conf_matrices = []\n",
    "test_conf_matrices = []\n",
    "\n",
    "def evaluate_knn_kfold(k_neighbors=5):\n",
    "    metrics = {\n",
    "        'train': {'accuracy': [], 'precision': [], 'recall': [], 'f1_macro': [], 'f1_weighted': [], 'f1_class0': [], 'f1_class1': []},\n",
    "        'test': {'accuracy': [], 'precision': [], 'recall': [], 'f1_macro': [], 'f1_weighted': [], 'f1_class0': [], 'f1_class1': []}\n",
    "    }\n",
    "    global train_conf_matrices, test_conf_matrices\n",
    "    train_conf_matrices = []\n",
    "    test_conf_matrices = []\n",
    "    label_column = 'y'\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        train_path = f'kfold_fold_{i}_train.csv'\n",
    "        test_path = f'kfold_fold_{i}_test.csv'\n",
    "        df_train = pd.read_csv(train_path)\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        X_train = df_train.drop(label_column, axis=1)\n",
    "        y_train = df_train[label_column]\n",
    "        X_test = df_test.drop(label_column, axis=1)\n",
    "        y_test = df_test[label_column]\n",
    "\n",
    "        model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        for dataset, y_true, y_pred in [('train', y_train, y_train_pred), ('test', y_test, y_test_pred)]:\n",
    "            metrics[dataset]['accuracy'].append(accuracy_score(y_true, y_pred))\n",
    "            metrics[dataset]['precision'].append(precision_score(y_true, y_pred, zero_division=0))\n",
    "            metrics[dataset]['recall'].append(recall_score(y_true, y_pred, zero_division=0))\n",
    "            metrics[dataset]['f1_macro'].append(f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
    "            metrics[dataset]['f1_weighted'].append(f1_score(y_true, y_pred, average='weighted', zero_division=0))\n",
    "            metrics[dataset]['f1_class0'].append(f1_score(y_true, y_pred, pos_label=0, zero_division=0))\n",
    "            metrics[dataset]['f1_class1'].append(f1_score(y_true, y_pred, pos_label=1, zero_division=0))\n",
    "\n",
    "        train_conf_matrices.append(confusion_matrix(y_train, y_train_pred))\n",
    "        test_conf_matrices.append(confusion_matrix(y_test, y_test_pred))\n",
    "        print(f\"Fold {i} - Train Accuracy: {metrics['train']['accuracy'][-1]:.4f}, Test Accuracy: {metrics['test']['accuracy'][-1]:.4f}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce79b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_knn_kfold(k_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ca932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Compare All Train vs Test Metrics\n",
    "folds = list(range(1, 11))\n",
    "measures = ['accuracy', 'precision', 'recall', 'f1_macro', 'f1_weighted', 'f1_class0', 'f1_class1']\n",
    "\n",
    "for measure in measures:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(folds, metrics['train'][measure], marker='o', label=f'Train {measure}')\n",
    "    plt.plot(folds, metrics['test'][measure], marker='o', label=f'Test {measure}')\n",
    "    plt.title(f'Train vs Test {measure.replace(\"_\", \" \").title()}')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel(measure.replace('_', ' ').title())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc663e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Summary Table: Mean and Std Dev of All Metrics\n",
    "import pandas as pd\n",
    "\n",
    "summary_data = {}\n",
    "for split in ['train', 'test']:\n",
    "    for metric, values in metrics[split].items():\n",
    "        summary_data[f'{split}_{metric}_mean'] = [np.mean(values)]\n",
    "        summary_data[f'{split}_{metric}_std'] = [np.std(values)]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data).T\n",
    "summary_df.columns = ['Value']\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Save Metrics to CSV\n",
    "fold_metrics = []\n",
    "for i in range(10):\n",
    "    row = {'Fold': i + 1}\n",
    "    for split in ['train', 'test']:\n",
    "        for metric in metrics[split]:\n",
    "            row[f'{split}_{metric}'] = metrics[split][metric][i]\n",
    "    fold_metrics.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(fold_metrics)\n",
    "metrics_df.to_csv('knn_fold_metrics.csv', index=False)\n",
    "print(\"Saved fold-wise metrics to knn_fold_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baaf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Export to Excel\n",
    "with pd.ExcelWriter('knn_metrics_report.xlsx') as writer:\n",
    "    metrics_df.to_excel(writer, index=False, sheet_name='Fold Metrics')\n",
    "    summary_df.to_excel(writer, sheet_name='Summary Stats')\n",
    "print(\"Saved metrics to knn_metrics_report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñº Export Line Charts as PNGs for Each Metric\n",
    "import os\n",
    "os.makedirs('metric_charts', exist_ok=True)\n",
    "\n",
    "for measure in measures:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(folds, metrics['train'][measure], marker='o', label=f'Train {measure}')\n",
    "    plt.plot(folds, metrics['test'][measure], marker='o', label=f'Test {measure}')\n",
    "    plt.title(f'Train vs Test {measure.replace(\"_\", \" \").title()}')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel(measure.replace('_', ' ').title())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'metric_charts/{measure}.png')\n",
    "    plt.close()\n",
    "print(\"Exported metric charts to the 'metric_charts' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© Save Confusion Matrices as PNGs\n",
    "os.makedirs('confusion_matrices/train', exist_ok=True)\n",
    "os.makedirs('confusion_matrices/test', exist_ok=True)\n",
    "\n",
    "for i in range(10):\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(train_conf_matrices[i]).plot(ax=ax)\n",
    "    plt.title(f'Train Confusion Matrix - Fold {i+1}')\n",
    "    plt.savefig(f'confusion_matrices/train/fold_{i+1}.png')\n",
    "    plt.close()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(test_conf_matrices[i]).plot(ax=ax)\n",
    "    plt.title(f'Test Confusion Matrix - Fold {i+1}')\n",
    "    plt.savefig(f'confusion_matrices/test/fold_{i+1}.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Confusion matrices saved to confusion_matrices/train/ and confusion_matrices/test/\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
