{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 28 10:25:04 2018\n",
    "\n",
    "@author: abinaya\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def preprocessing_features(df_train, df_test, process_continuous):\n",
    "    \n",
    "    to_delete_features = ['default','pdays']\n",
    "    continuous_features = ['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "    categorical_ordered_features = ['education', 'housing', 'loan', 'contact','month', 'day_of_week','poutcome']\n",
    "    categorical_unordered_features = ['job', 'marital']\n",
    "    \n",
    "    unknown_present_features = ['job','marital','education','housing','loan']\n",
    "    all_present_features = ['age', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'contact', 'month', 'day_of_week','poutcome']\n",
    "    \n",
    "    ### Delete Features\n",
    "    for feat in to_delete_features:\n",
    "        print(\"\\n--------- deleting feature --------- \", feat)\n",
    "        del df_train[feat]\n",
    "        del df_test[feat]\n",
    "        \n",
    "    ### Normalization or Standardization of Continuous Features\n",
    "    if process_continuous == \"Standardize\":\n",
    "        print(\"\\n--------- Standardizing Continuous Features (Mean=0, Standard Deviation=1) --------- \")\n",
    "        standardization = StandardScaler()\n",
    "        standardization.fit(df_train[continuous_features])\n",
    "        print(\"Mean: \", standardization.mean_)\n",
    "        print(\"Variance: \", standardization.var_)\n",
    "        df_train[continuous_features] = standardization.transform(df_train[continuous_features])\n",
    "        df_test[continuous_features] = standardization.transform(df_test[continuous_features])\n",
    "    \n",
    "    elif process_continuous == \"Normalize\":\n",
    "        print(\"\\n--------- Normalizing Continuous Features (Min=0, Max=1) --------- \")\n",
    "        min_max_scaling = MinMaxScaler()\n",
    "        min_max_scaling.fit(df_train[continuous_features])\n",
    "        print(min_max_scaling.data_min_)\n",
    "        print(min_max_scaling.data_max_)\n",
    "        df_train[continuous_features] = min_max_scaling.transform(df_train[continuous_features])\n",
    "        df_test[continuous_features] = min_max_scaling.transform(df_test[continuous_features])\n",
    "    \n",
    "        \n",
    "    ### Label Categorical Ordered Features -- Features used for Imputation (All Present)\n",
    "    label_dict = {'education':{'illiterate':0, 'basic.4y':4, 'basic.6y':6, 'basic.9y':9, 'high.school':11, 'professional.course':13, 'university.degree':14},\n",
    "                  'housing':{'no':0,'yes':1},\n",
    "                  'loan':{'no':0,'yes':1},\n",
    "                  'contact':{'telephone':0,'cellular':1},\n",
    "                  'month':{'jan':1,'feb':2,'mar':3,'apr':4,'may':5,'jun':6,'jul':7,'aug':8,'sep':9,'oct':10,'nov':11,'dec':12},\n",
    "                  'day_of_week':{'mon':1,'tue':2,'wed':3,'thu':4,'fri':5,'sat':6,'sun':7},\n",
    "                  'poutcome':{'nonexistent':0,'failure':1,'success':2}}\n",
    "    \n",
    "    for feat in categorical_ordered_features:\n",
    "        if feat not in unknown_present_features:\n",
    "            print(\"\\n--------- Labelling feature Before Imputation --------- \", feat)\n",
    "            df_train = df_train.replace({feat:label_dict[feat]})\n",
    "            df_test = df_test.replace({feat:label_dict[feat]})\n",
    "            print(\"Labelled as: \", label_dict[feat])\n",
    "         \n",
    "    ### Imputation using SVM\n",
    "    df_train_impute = df_train.loc[:,df_train.columns.isin(all_present_features)]\n",
    "    df_test_impute = df_test.loc[:,df_test.columns.isin(all_present_features)]\n",
    "    \n",
    "    for feat in unknown_present_features:\n",
    "        print(\"\\nFilling Unkowns for Feature: \", feat)\n",
    "        train_impute = df_train[feat]\n",
    "        test_impute = df_test[feat]\n",
    "        \n",
    "        train_impute_no_unknowns = train_impute[train_impute != 'unknown']\n",
    "        train_impute_unknowns = train_impute[train_impute == 'unknown']\n",
    "        test_impute_unknowns = test_impute[test_impute == 'unknown']\n",
    "        \n",
    "        df_train_impute_train_features = df_train_impute.loc[train_impute_no_unknowns.index]\n",
    "        df_train_impute_test_features = df_train_impute.loc[train_impute_unknowns.index]\n",
    "        df_test_impute_test_features = df_test_impute.loc[test_impute_unknowns.index]\n",
    "        \n",
    "        svm_model = SVC()\n",
    "        svm_model.fit(df_train_impute_train_features, train_impute_no_unknowns) \n",
    "        df_train.loc[df_train_impute_test_features.index, feat] = svm_model.predict(df_train_impute_test_features)\n",
    "        print(\"Train Filled with: \", df_train.loc[df_train_impute_test_features.index, feat].value_counts())\n",
    "        df_test.loc[df_test_impute_test_features.index, feat] = svm_model.predict(df_test_impute_test_features)\n",
    "        print(\"Test Filled with: \", df_test.loc[df_test_impute_test_features.index, feat].value_counts())\n",
    "    \n",
    "    ### Label Categorical Ordered Features -- Features Imputated (Unkowns were Present)\n",
    "    for feat in categorical_ordered_features:\n",
    "        if feat in unknown_present_features:\n",
    "            print(\"\\n--------- Labelling feature After  Imputation --------- \", feat)\n",
    "            df_train = df_train.replace({feat:label_dict[feat]})\n",
    "            df_test = df_test.replace({feat:label_dict[feat]})\n",
    "            print(\"Labelled as: \", label_dict[feat])\n",
    "            \n",
    "    ### One hot encoding Categorical Un-ordered Features  \n",
    "    for feat in categorical_unordered_features:\n",
    "        print(\"\\n--------- One Hot Encoding feature --------- \", feat)\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "    one_hot_encoder.fit(df_train[categorical_unordered_features])\n",
    "    one_hot_encoded_array_train = one_hot_encoder.transform(df_train[categorical_unordered_features])\n",
    "    one_hot_encoded_df_train = pd.DataFrame(one_hot_encoded_array_train, index=df_train.index)\n",
    "    one_hot_encoded_array_test = one_hot_encoder.transform(df_test[categorical_unordered_features])\n",
    "    one_hot_encoded_df_test = pd.DataFrame(one_hot_encoded_array_test, index=df_test.index)\n",
    "        \n",
    "    df_train = pd.concat([df_train,one_hot_encoded_df_train], axis=1, ignore_index=False) #concatenate old columns with new one hot encoded columns\n",
    "    df_test = pd.concat([df_test,one_hot_encoded_df_test], axis=1, ignore_index=False) #concatenate old columns with new one hot encoded columns\n",
    "    \n",
    "    df_train = df_train.drop(categorical_unordered_features, axis=1) #Delete columns which were one hot encoded\n",
    "    df_test = df_test.drop(categorical_unordered_features, axis=1) #Delete columns which were one hot encoded\n",
    "    \n",
    "    ### Return pre-processed df\n",
    "    return df_train, df_test\n",
    "\n",
    "def preprocessing_class(df_train, df_test):\n",
    "    \"\\n--------- Labelling Class Information --------- \"\n",
    "    class_col = 'y'\n",
    "    label_dict = {class_col:{'no':0,'yes':1}}\n",
    "    df_train = df_train.replace({class_col:label_dict[class_col]})\n",
    "    df_test = df_test.replace({class_col:label_dict[class_col]})\n",
    "    return df_train, df_test\n",
    "  \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
